{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00175c6-7235-4abf-9c0d-a131b6d170b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```python\n",
    "## \\file src/webdriver/llm_driver/simple_browser.py\n",
    "# -*- coding: utf-8 -*-\n",
    "#! .pyenv/bin/python3\n",
    "```\n",
    "Модуль для запуска задач с использованием LLM через LangChain и стандартных агентов.\n",
    "==================================================================================\n",
    "(Использует инструменты, взаимодействующие с BrowserController и/или API поиска)\n",
    "\n",
    "Предоставляет функциональность для:\n",
    "- Конфигурирования моделей (Gemini, OpenAI).\n",
    "- Установки API ключей.\n",
    "- Запуска задачи с использованием LLM и доступных инструментов (веб-поиск, браузер).\n",
    "- Выполнения задачи до конечного результата (`run_task`).\n",
    "- Стриминга выполнения задачи (`stream_task`).\n",
    "\n",
    "Зависимости:\n",
    "    - langchain-openai, langchain-google-genai, langchain-core, langchainhub, langchain\n",
    "    - langchain-community (для SerpAPIWrapper)\n",
    "    - google-search-results (для SerpAPIWrapper)\n",
    "    - python-dotenv\n",
    "    - browser_use (или ваш модуль с BrowserController)\n",
    "    - src.gs, src.logger, src.utils, header\n",
    "```rst\n",
    ".. module:: src.webdriver.llm_driver.simple_browser\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922ec09d-83d7-460b-9487-a15b5a3bf586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb # <- трасировка и точки останова\n",
    "import os\n",
    "import asyncio\n",
    "from types import SimpleNamespace\n",
    "from typing import List, Dict, Any, Optional, Callable, Type, Tuple, AsyncIterator\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain компоненты\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent, Tool\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.exceptions import LangChainException\n",
    "from langchain import hub\n",
    "# --- Инструмент для поиска через API ---\n",
    "# Убедитесь, что установлена: pip install google-search-results\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from browser_use import Agent\n",
    "\n",
    "# --- Внутренние модули ---\n",
    "import header\n",
    "from header import __root__\n",
    "from src import gs\n",
    "# from src.webdriver.ai_browser import tools\n",
    "# from src.webdriver.ai_browser.tools import get_tools, get_tools_by_type, get_tools_by_name\n",
    "from src.webdriver.llm_driver.use_llm import Config, Driver, stream_agent_execution\n",
    "\n",
    "from src.logger import logger\n",
    "from src.utils.jjson import j_loads, j_loads_ns\n",
    "from src.utils.printer import pprint as print\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6800e6-1d41-415f-9845-8925c5f48f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    ENDPOINT:Path = Path(__root__/'SANDBOX'/'davidka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c99e5-9452-4fc7-8b4e-669dd093951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDriver(Driver):\n",
    "    \"\"\"\"\"\"\n",
    "    def __init__(self, \n",
    "                 GEMINI_API_KEY:str = None, \n",
    "                 OPENAI_API_KEY:str = None, \n",
    "                 openai_model_name:str = None, \n",
    "                 gemini_model_name:str = None, \n",
    "                 start_browser:str = True,\n",
    "                **kwargs):\n",
    "        super().__init__(GEMINI_API_KEY, OPENAI_API_KEY, openai_model_name, gemini_model_name, start_browser, **kwargs) \n",
    "\n",
    "    async def simple_process_task_async(self, task:str = 'Hello, world!') -> Any:\n",
    "        \"\"\"\"\"\"\n",
    "\n",
    "        result_dict:dict = {}\n",
    "\n",
    "        def clean_json(raw_text: str) -> str:\n",
    "            # 1. Убираем всё до первой фигурной скобки {\n",
    "\n",
    "            json_start = raw_text.find('{')\n",
    "            if json_start == -1:\n",
    "                return raw_text  # нет скобки, вернуть как есть\n",
    "            # Извлекаем текст начиная с первой фигурной скобки\n",
    "            json_cleaned = raw_text[json_start:]\n",
    "    \n",
    "            # 2. Убираем завершающие тройные кавычки или лишние пробелы\n",
    "            json_cleaned = json_cleaned.strip('`\\n ')\n",
    "            \n",
    "            return json_cleaned\n",
    "\n",
    "        try:\n",
    "            # Инициализация агента с списком моделей и задачей\n",
    "            # Убедитесь, что ваш класс Agent может принимать список LLM объектов в параметре 'llm'\n",
    "            agent = Agent(\n",
    "                task=task,\n",
    "                llm=self.gemini, # Передача инициализированнoй модели\n",
    "                # Другие параметры для Agent, если они есть\n",
    "            )\n",
    "            logger.info(f\"Агент начинает выполнение задачи: \\\"{task}\\\"\")\n",
    "            answer: Any = await agent.run() # Ожидание результата работы агента\n",
    "            if not answer:\n",
    "                logger.error('Не вернулся результат действий агента')\n",
    "                ...\n",
    "            timestamp:str = gs.now\n",
    "\n",
    "            for action_result in answer.history:\n",
    "                result_list:list = getattr(action_result, 'result', None)\n",
    "                result:'ActionResult' = result_list[0]\n",
    "                extracted_content:str =\tresult.extracted_content\n",
    "\n",
    "                cleaned_json_text = clean_json(extracted_content)\n",
    "                try:\n",
    "                    data = j_loads(cleaned_json_text)  # Загружаем JSON из текста\n",
    "                    if not data: continue\n",
    "                except Exception as ex:\n",
    "                    logger.error(\"Ошибка разбора JSON\", ex, exc_info=True)\n",
    "                    ...\n",
    "                    continue\n",
    "\n",
    "                # Сохраняем данные\n",
    "                timestamp = gs.now\n",
    "                j_dumps(data, Config.ENDPOINT/'train_data_products'/f'product_links_{timestamp}.json')\n",
    "                result_dict.update(data)\n",
    "\n",
    "            logger.info(\"Агент завершил выполнение задачи.\")\n",
    "            ...\n",
    "            return result_dict \n",
    "        except Exception as agent_err:\n",
    "            logger.error(f\"\\n\\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!/nПроизошла ошибка во время инициализации или выполнения задачи агентом./n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!/n\", agent_err, exc_info=True)\n",
    "            ...\n",
    "            return '' # Возврат None при ошибке агента\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79907a87-6334-4ccb-af83-7aa0447674b7",
   "metadata": {},
   "source": [
    "```python\n",
    "## \\file /sandbox/davidka/crawler_simple_driver.py\n",
    "# -*- coding: utf-8 -*-\n",
    "#! .pyenv/bin/python3\n",
    "```\n",
    "Модуль для сбора данных со страниц товаров через SimpleDriver\n",
    "=====================================================\n",
    "(адаптация исходного crawler.py)\n",
    "```rst\n",
    ".. module:: sandbox.davidka.crawler_simple_driver\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649b671-4a0d-47e3-ba42-b61c0a90023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import header\n",
    "from header import __root__\n",
    "from src import gs\n",
    "from src.webdriver.llm_driver.simple_driver import SimpleDriver\n",
    "from src.utils.jjson import j_loads, j_dumps\n",
    "from src.utils.file import read_text_file, save_text_file, get_filenames_from_directory\n",
    "from src.utils.url import get_domain\n",
    "from src.utils.string.ai_string_utils import normalize_answer\n",
    "from src.utils.printer import pprint as print\n",
    "from src.logger import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f67341-1c7b-4b68-9487-31656768d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    ENDPOINT: Path = __root__ / 'SANDBOX' / 'davidka'\n",
    "    mining_data_path: Path = ENDPOINT / 'random_urls'\n",
    "    train_data_supplier_categories_path: Path = ENDPOINT / 'train_data_supplier_categories'\n",
    "    checked_domains: list = read_text_file(ENDPOINT / 'checked_domains.txt', as_list=True)\n",
    "    crawl_files_list: list = get_filenames_from_directory(mining_data_path, 'json')\n",
    "    instruction_grab_product_page_simple_driver: str = (ENDPOINT / 'instructions' / 'grab_product_page_simple_driver.md').read_text(encoding='utf-8')\n",
    "    instruction_get_supplier_categories: str = (ENDPOINT / 'instructions' / 'get_supplier_categories.md').read_text(encoding='utf-8')\n",
    "    instruction_find_product_in_supplier_domain: str = (ENDPOINT / 'instructions' / 'find_product_in_supplier_domain.md').read_text(encoding='utf-8')\n",
    "    instruction_for_products_urls_one_product: str = (ENDPOINT / 'instructions' / 'get_product_links_one_product.md').read_text(encoding='utf-8')\n",
    "    instruction_links_from_search: str = (ENDPOINT / 'instructions' / 'links_from_search.md').read_text(encoding='utf-8')\n",
    "    instruction_links_from_searh_page: str = (ENDPOINT / 'instructions' / 'links_from_searh_page.md').read_text(encoding='utf-8')\n",
    "    GEMINI_API_KEY = gs.credentials.gemini.katia.api_key\n",
    "    driver: SimpleDriver = SimpleDriver(gemini_model_name='gemini-1.5-flash-8b-exp-0924', GEMINI_API_KEY = GEMINI_API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb6b00-8db1-49cc-b60c-f7f70ab7dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products_urls_list_from_files(crawl_files_list: list = None) -> list:\n",
    "    \"\"\"Читает файлы с товарами и возвращает product_url списком\"\"\"\n",
    "    products_urls_list = []\n",
    "    for filename in crawl_files_list or Config.crawl_files_list:\n",
    "        try:\n",
    "            file_path = Config.mining_data_path / filename\n",
    "            crawl_data = j_loads(file_path)['products']\n",
    "            for product in crawl_data:\n",
    "                products_urls_list.append(product['product_url'])\n",
    "        except Exception as ex:\n",
    "            logger.error(f'Ошибка при обработке файла {filename=}', ex, exc_info=True)\n",
    "    random.shuffle(products_urls_list)\n",
    "    return products_urls_list\n",
    "\n",
    "\n",
    "def yield_product_urls_from_files(directory: Path = Config.mining_data_path, pattern: str = 'json'):\n",
    "    \"\"\"Генератор url товаров из файлов\"\"\"\n",
    "    filenames = get_filenames_from_directory(directory, pattern)\n",
    "    for filename in filenames:\n",
    "        try:\n",
    "            file_path = directory / filename\n",
    "            crawl_data = j_loads(file_path)['products']\n",
    "            for product in crawl_data:\n",
    "                yield product['product_url']\n",
    "        except Exception as ex:\n",
    "            logger.error(f'Ошибка при обработке файла {filename=}', ex, exc_info=True)\n",
    "\n",
    "\n",
    "def get_categories_from_random_urls(crawl_files_list: list = None) -> list:\n",
    "    \"\"\"Возвращает все категории из файлов товаров\"\"\"\n",
    "    categories_list = []\n",
    "    for filename in crawl_files_list or Config.crawl_files_list:\n",
    "        try:\n",
    "            file_path = Config.mining_data_path / filename\n",
    "            crawl_data = j_loads(file_path)\n",
    "            crawl_data = crawl_data.get('products', [])\n",
    "            for product in crawl_data:\n",
    "                if 'parent_category' in product:\n",
    "                    categories_list.append(product['parent_category'])\n",
    "                if 'category_name' in product:\n",
    "                    categories_list.append(product['category_name'])\n",
    "        except Exception as ex:\n",
    "            logger.error(f'Ошибка при обработке файла {filename=}', ex, exc_info=True)\n",
    "    categories_list = list(filter(None, set(categories_list)))\n",
    "    random.shuffle(categories_list)\n",
    "    return categories_list\n",
    "\n",
    "\n",
    "async def build_random_products_urls_by_category(category: str, task:str = '', num_of_links: str = '10') -> str:\n",
    "    \"\"\"Получить товары по категории\"\"\"\n",
    "    try:\n",
    "        driver = Config.driver\n",
    "        logger.info(f'Обработка {category=}')\n",
    "        \n",
    "        task = task or Config.instruction_links_from_searh_page.replace('{PRODUCT_CATEGORY}', category).replace('{NUM_LINKS}', num_of_links)\n",
    "        #ipdb.set_trace()\n",
    "        answer = await driver.simple_process_task_async(task)\n",
    "        if not answer:\n",
    "            return ''\n",
    "        print('\\n -------------------------------- EXTRACTED DATA \\n------------------------------------------\\n')\n",
    "        print(answer)\n",
    "        print('\\n -------------------------------------------------------------------------------------------')\n",
    "        save_text_file(answer, Path(f'F:/llm/random_products_links/{gs.now}.json'))\n",
    "        return answer\n",
    "    except Exception as ex:\n",
    "        logger.error(f'Ошибка при обработке {category=}', ex, exc_info=True)\n",
    "        return ''\n",
    "\n",
    "\n",
    "async def fetch_categories_from_suppliers_random_urls() -> dict:\n",
    "    \"\"\"Сбор категорий с сайтов\"\"\"\n",
    "    categories_dict = {}\n",
    "    driver = Config.driver\n",
    "\n",
    "    for filename in Config.crawl_files_list:\n",
    "        try:\n",
    "            file_path = Config.mining_data_path / filename\n",
    "            crawl_data = j_loads(file_path)\n",
    "            crawl_data = crawl_data.get('products', [])\n",
    "            for product in crawl_data:\n",
    "                domain = get_domain(product['product_url'])\n",
    "                if domain in Config.checked_domains:\n",
    "                    continue\n",
    "                task = Config.instruction_get_supplier_categories.replace('{INPUT_URL}', domain)\n",
    "                res = await driver.simple_process_task_async(task)\n",
    "                if not res:\n",
    "                    continue\n",
    "                normalized_res = normalize_answer(res.get('output', ''))\n",
    "                data = j_loads(normalized_res)\n",
    "                print(data)\n",
    "                j_dumps(data, Config.train_data_supplier_categories_path / f'{gs.now}.json')\n",
    "                Config.checked_domains.append(domain)\n",
    "                save_text_file(Config.checked_domains, Config.ENDPOINT / 'checked_domains.txt')\n",
    "                j_dumps(Config.checked_domains, Config.ENDPOINT / 'checked_domains.json')\n",
    "        except Exception as ex:\n",
    "            logger.error(f'Ошибка при обработке файла {filename=}', ex, exc_info=True)\n",
    "    return categories_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9568bd-ee6c-4a51-9c1b-d6248b82428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver = Config.driver\n",
    "\n",
    "# Пример: обработка товаров по категориям\n",
    "for category in get_categories_from_random_urls():\n",
    "    #ipdb.set_trace()\n",
    "    if not await build_random_products_urls_by_category(category = category, num_of_links = '10'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff28ed5-5f08-4a92-8282-949542be9c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02fe849-8485-4317-95ef-aedfe571ef11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
